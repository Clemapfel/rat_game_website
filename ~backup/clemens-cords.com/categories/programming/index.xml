<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <docs>https://blogs.law.harvard.edu/tech/rss</docs>
    <title >programming on Clemens Cords&#39; Homepage</title>
    <link>http://clemens-cords.com/categories/programming/</link>
    <description>Recent content in programming on Clemens Cords&#39; Homepage</description>
    <image>
      <title>programming on Clemens Cords&#39; Homepage</title>
      <link>http://clemens-cords.com/categories/programming/</link>
      <url>http://clemens-cords.com/rat_icon.png</url>
    </image>
    <ttl>1440</ttl>
    <generator>After Dark 9.2.3 (Hugo 0.68.3)</generator>
    <language>en-US</language>
    <lastBuildDate>Sun, 06 Mar 2022 19:49:27 UT</lastBuildDate>
    <atom:link href="http://clemens-cords.com/categories/programming/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[WIP] A fast, robust Boundary Tracing and Enumeration Algorithm</title>
      <link>http://clemens-cords.com/post/boundary_tracing_algorithm/</link>
      <pubDate>Thu, 29 Jul 2021 22:00:00 UT</pubDate>
      <dc:creator>C. Cords</dc:creator>
      <guid>http://clemens-cords.com/post/boundary_tracing_algorithm/</guid>
      <description>Abstract Boundaries are central to many field in image processing and having a way to numerically represent them is the only way to build libraries of them for later feature detection. Here I present the algorithm used by crisp::ImageRegion that extracts from a region consisting of a set of 4 (8)-connected pixel coordinates all it&amp;rsquo;s outer boundary points and enumerates them in a deterministic manner. The region has to fullfill no further constraints.</description>
      <category domain="http://clemens-cords.com/categories/programming">Programming</category>
      <category domain="http://clemens-cords.com/categories/crisp">Crisp</category>
      <content:encoded><![CDATA[Abstract Boundaries are central to many field in image processing and having a way to numerically represent them is the only way to build libraries of them for later feature detection. Here I present the algorithm used by crisp::ImageRegion that extracts from a region consisting of a set of 4 (8)-connected pixel coordinates all it&amp;rsquo;s outer boundary points and enumerates them in a deterministic manner. The region has to fullfill no further constraints. The algorithm runs in amortized o(x &#43; k) where x is the number of pixels in the region and k are the number of boundary pixels. The advantage of the method presented here is not only a robustness to common edge cases making user-input minimal but that both the freeman-chain codes and the minimum-vertex boundary polygon can be extracted at the end of the algorithm in o(1).
[(skip to source code)](#The Algorithm)
Introduction Boundary tracing it such an elemental task in image processing because boundaries are one of the best features to classify and many other features descriptors work as a function of boundary. Crisp for example uses the fourier transform of a boundary converted onto the complex plane (such that each vertices x position is the real, y position the complex part respectively) for boundary simplification and when I went to consult the literature I was frustrated that many of the common algorithms don&amp;rsquo;t fullfill the following two demands I somewhat arbitrarily set myself:
  i) the algorithm should work on all closed regions, no exceptions Common assumptions algorithms make are &amp;ldquo;let the region be simply connected&amp;rdquo; or &amp;ldquo;let the region boundary be non-overlapping&amp;rdquo;. I want crisps algorithm to be able to handle all of these with not further user interaction, indeed the only assertion crisp makes is that the region is closed and connected which for image-processing purposes is an assumption that&amp;rsquo;s made for all common segmentation algorithms anyway. If the region is not connected you can simply decompose them into connected segments, then the boundary of the original non-connected region is the union of the boundary of all segments
  ii) the resulting boundary should have the minimum number of points necessary to represent the region with no loss of detail To build a library of boundaries you need to transform them and that transformation should be as computationally as possible and crisp achieves this by returning the boundary polygon, a set of ordeted vertices that when connected are identical to the set of boundary points.
  iii) the resulting order of boundary points should be circular, consistent and predictable it is not difficult to isolate the set of boundary points from a region, however we want those points to have a strong order that makes sense to both humans and computers. crisp wants the vertex to orderd in the counter-clockwise with the position x-axis advancing to the east and the positive y-axis advancing south in 2d space. This order being consistent means for two sets such that the intersection of the two is empty, the algorithm should return two boundary point sequences that are identical. Circularity means that if we index the points with i = 0 &amp;hellip; N then point p_0 needs to be connected to p_1 and p_N, more on this constraint below
  These three conditions need to be fullfilled at the same time of course. I&amp;rsquo;ve used quite a few terms without properly defining them so far so let&amp;rsquo;s get that out of the way
Definitions A image region M of an Image I is defined as a finite set of pixels that is a subset of an image of size m*n such that the following conditions hold:
 for any two pixel x in M there is a different pixel x_n such that x and x_n are 8-connected. M is a subset of I  A boundary can be intuitively described as the outer most pixels of the region that are still a subset of it. Each pixel in the boundary can be approached both from inside M and from the space around M. Formally a boundary K = {p_0, p_1, &amp;hellip;, p_n} is a set of pixels such that
 A: K is a subset of M, this makes M a closed region B: for any pixel p_i in K it holds that p_i-1 is 8-connected to p_i and p_i is 8-connected to p_i&#43;1. p_0 is 8-connected to p_n, this makes the boundary circular C: any pixel y in K has less than 8 neighbors in M, this means in image space y has at least 1 pixel that is not part of the region D: K is not the boundary of a hole (TODO: define hole)  A boundary K is minimal if there exists no pixel p_i such that K - p_i (the set difference) is still 8-connected and fullfills condition B, see above
A boundary polygon P = {v_0, v_1, &amp;hellip;, v_n} is a set of vertices such that if you draw a 1-pixel thick line from v_0 to v_1, v_1 to v_2, &amp;hellip;, v_m-1 to v_m in image space then the set of pixels covered by these lines is identical to the boundary K.
On minimality, it&amp;rsquo;s best to show visually what it means to be minimal, of course we want our set to be as small as possible for performance reason but visually it means that some pixels with only 1 non-M neighbor should be ommitted as such:
 Figure 1 An 8-connected region (A), a boundary (B) and the minimal boundary (C)  As state in the definition if we remove any boundary (white) pixel in C we would either loose detail from the original region or make it so there&amp;rsquo;s an unconnected gap in the sequence of boundary points.
The Algorithm Now that we know what we&amp;rsquo;re trying to do let&amp;rsquo;s first get the actual algorithm out of the way. An step-by-step explanation will follow below
// in BinaryImage image; // image that is true if the pixel is part of a closed region, false otherwise  // out std::vector&amp;lt;Vector2ui&amp;gt; boundary; std::vector&amp;lt;Vector2ui&amp;gt; boundary_polygon; size_t n_holes; // ### STEP 1: pre-process the image bool segment_color = true; // white  // fill all 1-pixel holes for (long x = 0; x &amp;lt; image.get_size().x(); &#43;&#43;x) { for (long y = 0; y &amp;lt; image.get_size().y(); &#43;&#43;y) { if (image(x, y) == segment_color) continue; // count 4-connected neighbors that are part of the region  size_t n = 0; for (std::pair&amp;lt;int, int&amp;gt; i_j : {{-1, 0}, {1, 0}, {0, -1}, {0, 1}}) { if (image(x &#43; i_j.first, y &#43; i_j.second) == segment_color) n&#43;&#43;; } if (n &amp;gt;= 3) image(x, y) = segment_color; } } // prune all 1-pixel lines std::vector&amp;lt;Vecto2ui&amp;gt; pruned; while (true) { n_changed = 0; for (long x = 0; x &amp;lt; image.get_size().x(); &#43;&#43;x) { for (long y = 0; y &amp;lt; image.get_size().y(); &#43;&#43;y) { if (image(x, y) != segment_color) continue; size_t n = 0; for (std::pair&amp;lt;int, int&amp;gt; i_j : {{-1, 0}, {1, 0}, {0, -1}, {0, 1}}) { if (image(x &#43; i_j.first, y &#43; i_j.second) == segment_color) n&#43;&#43;; } if (n == 1) { image(x, y) = not segment_color; n_changed&#43;&#43;; } } } if (n_changed == 0) break; } // ### STEP 2: extract the segment struct PixelCoordCompare { bool operator()(const Vector2ui&amp;amp; a, const Vector2ui&amp;amp; b) const { return a.y() != b.y() ? a.y() &amp;lt; b.y() : a.x() &amp;lt; b.x(); } }; using PixelSet = std::set&amp;lt;Vector2ui, detail::PixelCoordCompare&amp;gt;; std::vector&amp;lt;PixelSet&amp;gt; segments = crisp::decompose_into_connected_segments(image, {true}); PixelSet segment = segments.at(0); // ### STEP 3: isolate all possible boundary points  PixelSet strong_pixels, // 100% part of b oundary  weak_pixels; // may be needed for continuing in edge cases  for (auto&amp;amp; px : segment) { size_t n_unconnected = 0; for (long i = -1; i &amp;lt;= &#43;1; &#43;&#43;i) { for (long j = -1; j &amp;lt;= &#43;1; &#43;&#43;j) { if (not (i == 0 and j == 0) and segment.find(Vector2ui(px.x() &#43; i, px.y() &#43; j)) == segment.end()) n_unconnected&#43;&#43;; } } if (n_unconnected &amp;gt; 1) strong_pixels.insert(px); else if (n_unconnected == 1) weak_pixels.insert(px); } // ### STEP 4: define the direction function  auto translate_in_direction = [&amp;amp;](Vector2ui point, uint8_t direction) -&amp;gt; Vector2ui { direction = direction % 8; int x_offset, y_offset; switch (direction) { case 0: // WEST  x_offset = -1; y_offset = 0; break; case 1: // SOUTH WEST  x_offset = -1; y_offset = &#43;1; break; case 2: // SOUTH  x_offset = 0; y_offset = &#43;1; break; case 3: // SOUTH EAST  x_offset = &#43;1; y_offset = &#43;1; break; case 4: // EAST  x_offset = &#43;1; y_offset = 0; break; case 5: // NORTH EAST  x_offset = &#43;1; y_offset = -1; break; case 6: // NORTH  x_offset = 0; y_offset = -1; break; case 7: // NORTH_WEST  x_offset = -1; y_offset = -1; break; } return Vector2ui(point.x() &#43; x_offset, point.y() &#43; y_offset); }; // ### STEP 5: Initialize the Tracing  // output, each index holds 1 boundary object where the first one is the outer boundary and every subsequent one is the outline of a hole std::vector&amp;lt;std::vector&amp;lt;Vector2ui&amp;gt;&amp;gt; boundaries_out; std::vector&amp;lt;std::vector&amp;lt;uint8_t&amp;gt;&amp;gt; directions_out; while (strong_pixels.size() &amp;gt; 0) { boundaries_out.emplace_back(); directions_out.emplace_back(); auto&amp;amp; boundary = boundaries_out.back(); auto&amp;amp; direction = directions_out.back(); auto top_left = *strong_pixels.begin(); boundary.push_back(top_left); strong_pixels.erase(top_left); direction.push_back(0); size_t current_i = 0; // ### STEP 6 trace and push once tracing complete  do { // current pixel  auto current = boundary.at(current_i); auto current_direction = direction.at(current_i); // was a candidate found  bool found = false; // check strong candidates  for (int dir = current_direction - 1, n = 0; n &amp;lt; 8; &#43;&#43;dir, &#43;&#43;n) { auto to_check = translate_in_direction(current, dir); if (to_check.x() &amp;lt; _x_bounds.x() or to_check.x() &amp;gt; _x_bounds.y() or to_check.y() &amp;lt; _y_bounds.x() or to_check.y() &amp;gt; _y_bounds.y()) continue; // check for convergence by looping back to the starting pixel  if (to_check == top_left) finished_maybe = true; if (strong_pixels.find(to_check) != strong_pixels.end()) { // push new pixel from set to boundary  boundary.push_back(to_check); direction.push_back(dir); strong_pixels.erase(to_check); found = true; break; } } // if we already found a strong candidate we can just jump to the next  if (found) { current_i = boundary.size() - 1; continue; } // if no strong candidate was found even though we looped back, we are back at the start  // c.f. explanation below  else if (finished_maybe) break; // if no strong candidate was found, check weak candidates  for (int dir = current_direction - 1, n = 0; n &amp;lt; 8; &#43;&#43;dir, &#43;&#43;n) { auto to_check = translate_in_direction(current, dir); if (to_check.x() &amp;lt; _x_bounds.x() or to_check.x() &amp;gt; _x_bounds.y() or to_check.y() &amp;lt; _y_bounds.x() or to_check.y() &amp;gt; _y_bounds.y()) continue; if (weak_pixels.find(to_check) != weak_pixels.end()) { boundary.push_back(to_check); direction.push_back(dir); weak_pixels.erase(to_check); found = true; break; } } if (found) { current_i = boundary.size() - 1; continue; } // if neither weak nor strong candidate found, start traceback  else current_i--; } while (current_i != 0); // ### STEP 7: reduce to non-redundant polygon vertices outer_boundary = boundaries_out.at(0); outer_boundary_directions = directions_out.at(0); size_t n_holes = boundaries_out.size() - 1; // all boundary at position &amp;gt; 0 are those of holes  // define function to detect if two vertices in a sequence are colinear auto turn_type = [&amp;amp;](size_t i_a, size_t i_b) -&amp;gt; int { auto point_a = outer_boundary.at(i_a), point_b = outer_boundary.at(i_b); // warp point from traceback  if (abs(int(point_a.x()) - int(point_b.x())) &amp;gt; 1 or abs(int(point_a.y()) - int(point_b.y())) &amp;gt; 1) return 0; auto dir_a = outer_boundary_directions.at(i_a), dir_b = outer_boundary_directions.at(i_b); if (dir_b &amp;gt; dir_a or (dir_a == 7 and dir_b == 0)) return -1; // left-hand turn  else if (dir_b &amp;lt; dir_a or (dir_a == 0 and dir_b == 7)) return &#43;1; // right-hand turn  else return 0; // colinear }; auto boundary_polygon_out = std::vector&amp;lt;Vector2ui&amp;gt;(); Vector2f mean_pos = Vector2f(0, 0); // discard all colinear vertices but preserve order for (size_t i = 0; i &amp;lt; _boundary.size() - 1; &#43;&#43;i) if (turn_type(i, i&#43;1) != 0) boundary_polygon_out.push_back(_boundary.at(i)); return boundary_polygon_out; Step 1: Pre Processing We first need to pre-process the image, 1-pixel holes and gaps and 1-pixel thick lines will cause problems later on so we need to remove them. Often these features happen purely because of noise and even if you would need them to be part of the actual region because you&amp;rsquo;re working on that small a resolution you can simply scale the image by a factor of 2 and the automated pre-processing step will leave them untouched.
To fill all 1-pixel holes we iterate through the region M (here represented as a binary image) and for each pixel count the number of 4-connected neighboring pixels that are also in M. If at least 3 of them are we found a hole or gap that needs to be patch
// fill all 1-pixel holes for (long x = 0; x &amp;lt; image.get_size().x(); &#43;&#43;x) { for (long y = 0; y &amp;lt; image.get_size().y(); &#43;&#43;y) { // only iterate through region  if (image(x, y) == segment_color) continue; size_t n = 0; // count for connected neighbors  for (std::pair&amp;lt;int, int&amp;gt; i_j : {{-1, 0}, {1, 0}, {0, -1}, {0, 1}}) { if (image(x &#43; i_j.first, y &#43; i_j.second) == segment_color) n&#43;&#43;; } // make that pixel part of the region by setting it to the specified color (black)  if (n &amp;gt;= 3) image(x, y) = segment_color; } }  Figure 2: Left: Segmented region corrupted by noise, Right: Region after filling all 1-pixel holes (newly assigned pixels shown in purple)  We now need to prune all 1-pixel thick lines. We do this recursively (there&amp;rsquo;s more optimal ways to do this that have a far less performance overhead but for the sake of simplicity I will demonstrate the recursive method here. Optimally you would use a subtract a morphological hit-or-miss-transform that detects the lines from the original image) by &amp;ldquo;eating away&amp;rdquo; at the end of each line and repeat until no more lines are left:
// prune all 1-pixel lines while (true) { // count number of changed pixels  n_changed = 0; for (long x = 0; x &amp;lt; image.get_size().x(); &#43;&#43;x) { for (long y = 0; y &amp;lt; image.get_size().y(); &#43;&#43;y) { if (image(x, y) != segment_color) continue; // count number of 4-connected neighbors in M  size_t n = 0; for (std::pair&amp;lt;int, int&amp;gt; i_j : {{-1, 0}, {1, 0}, {0, -1}, {0, 1}}) { if (image(x &#43; i_j.first, y &#43; i_j.second) == segment_color) n&#43;&#43;; } // if it only has 1 neighbor it is the end of a line, prune it  if (n == 1) { image(x, y) = not segment_color; n_changed&#43;&#43;; } } } // if no lines changed, we converged  if (n_changed == 0) break; }  Figure 3: Left: Region after filling all 1-pixel holes, Right: Pruned region, removed pixels shown in purple with increased lightness as the number of iterations increases  Note that we leave a &amp;ldquo;stump&amp;rdquo; of size 1-pixel, if this throws of later processing feels free to first erode then dilate the area with a 2x2 structuring element. Morphological processing in general can make this process faster and cleaner but for now we will do it recursively like this.
Now that our region as an image is primed we can transform it into a region as a mathematical set of coordinates.
Step 2: Extract the Region We first define a new typedef PixelSet, this is a set that takes a custom comparator such that the pixel coordinates in the set are ordered left-to-right, top-to-bottom which means the first pixel is the pixel with the smalle x- and y- coordinate, if two pixels share a x-coordinate, the pixel with the lower y-coordinate comes first. Remember that our coordinate systems x-axis extends to right of the image, the y-axis to the bottom so a higher y-value means the pixel is lower down.
struct PixelCoordCompare { bool operator()(const Vector2ui&amp;amp; a, const Vector2ui&amp;amp; b) const { return a.y() != b.y() ? a.y() &amp;lt; b.y() : a.x() &amp;lt; b.x(); } }; using PixelSet = std::set&amp;lt;Vector2ui, detail::PixelCoordCompare&amp;gt;; std::vector&amp;lt;PixelSet&amp;gt; segments = crisp::decompose_into_connected_segments(image, {true}); PixelSet segment = segments.at(0); The actual extraction of the set is left to another crisp function, to learn more about it you can check the documentation HERE TODO. It extracts all 4-connected segments, let&amp;rsquo;s assume our segment is the only one in the image so the only set in the vector is the set of all pixel coordinates M.
Step 3: Isolate all Boundary Pixels A boundary pixel by definition is a pixel that has a neighbor in image space that is not part of M. Much like in our pre-processing steps we can simply iterate through the set and count the number of pixels with less than 8 neighbors. We furthermore devide these into weak and strong boundary candidates. A weak candidate is a pixel with exactly 1 non-M neighbour, a strong candidate is a pixel with 2 or more non-M neighbours. The reason for this seperation will come into play shortly
PixelSet strong_pixels, weak_pixels; for (auto&amp;amp; px : segment) { // count non-M neighbours  size_t n_unconnected = 0; for (long i = -1; i &amp;lt;= &#43;1; &#43;&#43;i) { for (long j = -1; j &amp;lt;= &#43;1; &#43;&#43;j) { if (not (i == 0 and j == 0) and segment.find(Vector2ui(px.x() &#43; i, px.y() &#43; j)) == segment.end()) n_unconnected&#43;&#43;; } } // 2 or more -&amp;gt; strong  if (n_unconnected &amp;gt; 1) strong_pixels.insert(px); // exactly 1 -&amp;gt; weak  else if (n_unconnected == 1) weak_pixels.insert(px); }  Figure 4: Left: Region from step 3, Right: Region with strong boundary candidates highlighted in green, weak candidates highlighted in red.  Step 5: Define the direction function One more thing before we can finally start tracing the boundary, we need to define a function that defines the direction of two pixels in the boundary. Let p_i, p_i&#43;1 be two pixels in K, then we can visualize the following directions as &amp;ldquo;to travel from p_i to p_i&#43;1 we need to go one pixel x&amp;rdquo; where x is the direction. So for x = &amp;ldquo;south west&amp;rdquo;, we need to travel one pixel to the bottom and one pixel to the right in image space. We get 8 direction like this and we assign each direction a number: 0 = west, 1 = south west, 2 = south and so on in clockwise direction (the boundary is traced in counterclockwise direction while this direction mapping function assigns values clockwise). We then end up with 7 = north west after which we loop back to 0 = west. To do ths looping we take the modulo of the direction before returning the appropriate next pixel.
auto translate_in_direction = [&amp;amp;](Vector2ui point, uint8_t direction) -&amp;gt; Vector2ui { direction = direction % 8; int x_offset, y_offset; switch (direction) { case 0: // WEST: p_i&#43;1 is right of p_i  x_offset = -1; y_offset = 0; break; case 1: // SOUTH WEST: p_i is  x_offset = -1; y_offset = &#43;1; break; case 2: // SOUTH  x_offset = 0; y_offset = &#43;1; break; case 3: // SOUTH EAST  x_offset = &#43;1; y_offset = &#43;1; break; case 4: // EAST  x_offset = &#43;1; y_offset = 0; break; case 5: // NORTH EAST  x_offset = &#43;1; y_offset = -1; break; case 6: // NORTH  x_offset = 0; y_offset = -1; break; case 7: // NORTH_WEST  x_offset = -1; y_offset = -1; break; } return Vector2ui(point.x() &#43; x_offset, point.y() &#43; y_offset); }; It is important to really understand this function, for tracing to work properly we need to know what direction we just went to get from p_i-1 to p_i, let&amp;rsquo;s say &amp;ldquo;south&amp;rdquo; (which is the value 2) then when looking for the next pixel around p_i we need to start looking first at south - 1 = south west, if no match was found look south next, south east afterwards, etc.. Doing it like this will assure that our tracing can&amp;rsquo;t get stuck in loops.
Step 6: Tracing We first need to initialize the algorithm, we open a vector that holds confirmed boundary points and a vector of directions that holds the corresponding direction. So when the boundary point is at position j in the vector then the direction vector will have the direction travele from p_j-1 to p_j at position j.
(the following algorithm is missing certain parts of the full algorithm above, this is for ease of explaining, we will get to what other things we need to do later).
auto&amp;amp; boundary = std::vector&amp;lt;Vector2ui&amp;gt;(); auto&amp;amp; direction = std::vector&amp;lt;uin8_t&amp;gt;(); auto top_left = *strong_pixels.begin(); boundary.push_back(top_left); strong_pixels.erase(top_left); direction.push_back(0); We also initialize the first boundary point which is the top-most left-most strong pixel. Because our custom PixelSet orders points in just this way, the first pixel in the set is also the top-most, left-most one. We then initialize the directions with 0 (west). We can now start tracing.
size_t current_i = 0; do { // current pixel and direction  auto current = boundary.at(current_i); auto current_direction = direction.at(current_i); // boolean to track if a proper candidate was found yet  bool found = false; // check strong candidates  // we start at the last direction -1 (counterclockwise before the other)  // and go through all possible directions, here counted with n  for (int dir = current_direction - 1, n = 0; n &amp;lt; 8; &#43;&#43;dir, &#43;&#43;n) { // we check the next pixel as directed by the direction function mentioned above  auto to_check = translate_in_direction(current, dir); // skip if out of bounds  if (to_check.x() &amp;lt; _x_bounds.x() or to_check.x() &amp;gt; _x_bounds.y() or to_check.y() &amp;lt; _y_bounds.x() or to_check.y() &amp;gt; _y_bounds.y()) continue; // this will be important for convergene, ignore it for now  //if (to_check == top_left)  // finished_maybe = true;  //if a strong pixel was found  if (strong_pixels.find(to_check) != strong_pixels.end()) { // add it to confirmed boundary points  boundary.push_back(to_check); // add it corresponding direction  direction.push_back(dir); // scrub it from the set of possible boundary points  strong_pixels.erase(to_check); // say that we found a candidate  found = true; break; } } // if we already found a strong candidate we can just jump to the next  if (found) { // reset current_i to the pixel last pushed  current_i = boundary.size() - 1; // and skip the rest of the loop  continue; } (...) Again, some of the loop was left out for clarity for now. We start at the top left and then check if any of the pixels in it&amp;rsquo;s 8-connected neighborhood are also in M. If yes, we found a boundary pixel and can push it and now search the 8-connected neighborhood around it. As mentioned above keeping track of the direction is important to enforce a strong order, if we arrived via direction d at pixel p_i (from p_i-1) then we should start checking pixels at direction d-1 next. d-1 is left of d because the directions are numerate clockwise. If we don&amp;rsquo;t find a pixel there, try the next direction and so on.
Now you might think we are done. We just go through all the pixels and since all strong pixels are linked, it&amp;rsquo;ll just finish, right? Well not quite. Consider our region from earlier:
 Figure 6: State of the tracing algorithm after 44 iterations. The compass wheel on the top shows the directions where ``mint = east``, ``red = west``, ``pink = north``, ``cyan = south``, etc.. The corresponding direction for each point p_i is shown in color. The yellow point is the starting point. On the right the boundary so far is highlighted in white.  We&amp;rsquo;re stuck! We&amp;rsquo;ve only been using strong pixels so far and we&amp;rsquo;ve gotten to a point where there&amp;rsquo;s no other strong pixel in the 8-neighborhood. We kept track of the weak pixels for just this occassion, because:
(the previous code is reposts here for convenience)
do { auto current = boundary.at(current_i); auto current_direction = direction.at(current_i); bool found = false; // check strong candidates  for (int dir = current_direction - 1, n = 0; n &amp;lt; 8; &#43;&#43;dir, &#43;&#43;n) { auto to_check = translate_in_direction(current, dir); if (to_check.x() &amp;lt; _x_bounds.x() or to_check.x() &amp;gt; _x_bounds.y() or to_check.y() &amp;lt; _y_bounds.x() or to_check.y() &amp;gt; _y_bounds.y()) continue; // check for convergence by looping back to the starting pixel  if (to_check == top_left) finished_maybe = true; if (strong_pixels.find(to_check) != strong_pixels.end()) { // push new pixel from set to boundary  boundary.push_back(to_check); direction.push_back(dir); strong_pixels.erase(to_check); found = true; break; } } // if we already found a strong candidate we can just jump to the next  if (found) { current_i = boundary.size() - 1; continue; } // if no strong candidate was found, check weak candidates  for (int dir = current_direction - 1, n = 0; n &amp;lt; 8; &#43;&#43;dir, &#43;&#43;n) { // same thing as with strong candidates, just with the weak_pixels set  auto to_check = translate_in_direction(current, dir); if (to_check.x() &amp;lt; _x_bounds.x() or to_check.x() &amp;gt; _x_bounds.y() or to_check.y() &amp;lt; _y_bounds.x() or to_check.y() &amp;gt; _y_bounds.y()) continue; if (weak_pixels.find(to_check) != weak_pixels.end()) { boundary.push_back(to_check); direction.push_back(dir); weak_pixels.erase(to_check); found = true; break; } } // if we found a weak pixel we can continue  if (found) { current_i = boundary.size() - 1; continue; } } while (current_i != 0); We now do just the same thing for weak pixels but we want to prioritize the strong ones always but now that we would be stuck without them we fall back and add 1 weak pixel:
 Figure 6: State of the tracing algorithm after 44 iterations. The compass wheel on the top shows the directions where ``mint = east``, ``red = west``, ``pink = north``, ``cyan = south``, etc.. The corresponding direction for each point p_i is shown in color. The yellow point is the starting point. On the right the boundary so far is highlighted in white.  ]]></content:encoded>
    </item>
    <item>
      <title>[WIP] Choosing initial Cluster Centers for use in RGB Image Segmentation using k-means clustering</title>
      <link>http://clemens-cords.com/post/k-means_heuristic/</link>
      <pubDate>Thu, 29 Jul 2021 22:00:00 UT</pubDate>
      <dc:creator>C. Cords</dc:creator>
      <guid>http://clemens-cords.com/post/k-means_heuristic/</guid>
      <description>Abstract TODO
The Algorithm First we initialize the cluster centers (how exactly this is done will be explained later)
using namespace crisp; struct Cluster { Color color_sum; size_t n; Color mean_color; } std::vector&amp;lt;Cluster&amp;gt; clusters; for (size_t i = 0; i &amp;lt; n_clusters; &#43;&#43;i) { Color color = // heuristically choosen, see below  clusters.push_back(Cluster{color, 1, color}); } Here n is the number of pixels currently in the cluster, color_sum is the sum of the rgb color and mean_color is the current color assigned to the entire cluster.</description>
      <category domain="http://clemens-cords.com/categories/programming">Programming</category>
      <category domain="http://clemens-cords.com/categories/crisp">Crisp</category>
      <content:encoded><![CDATA[Abstract TODO
The Algorithm First we initialize the cluster centers (how exactly this is done will be explained later)
using namespace crisp; struct Cluster { Color color_sum; size_t n; Color mean_color; } std::vector&amp;lt;Cluster&amp;gt; clusters; for (size_t i = 0; i &amp;lt; n_clusters; &#43;&#43;i) { Color color = // heuristically choosen, see below  clusters.push_back(Cluster{color, 1, color}); } Here n is the number of pixels currently in the cluster, color_sum is the sum of the rgb color and mean_color is the current color assigned to the entire cluster.
We then specify a distance measure, for this variant the euclidian distance in rgb space is sufficient. Quantizing the possible values (remember, our Colors are floating point vectors which each element in the range [0, 1]) aids in performance
auto distance = [](Color a, Color b) -&amp;gt; int { int score = abs(int(a.red() * 255) - int(b.red() * 255)) &#43; abs(int(a.green() * 255) - int(b.green() * 255)) &#43; abs(int(a.blue() * 255) - int(b.blue() * 255)); return score; } We quantize the color components to 8-bit and then compute the euclidian distance ommitting the square root and square operations for improved performance as no normalization is necessary. Note that this function will return values in the range of [0, 3*255].
The algorithm is initialized by first allocating the result image. To save on performance we use the image itself as a way to keep track of which pixel is in which clusters. Since the result image is an RGB image we arbitrarily declare the .red() component to be the cluster index (range {0, 1, 2, &amp;hellip;, n_clusters - 1}) while all other components are set to 0. While color components can only be in the range [0, 1] for display, crisp allows you to freely set the values while the images are still in memory. The range is only enforced when binding an image for rendering.
ColorImage out; // .r is cluster index out.create(image.get_size().x(), image.get_size().y(), Color(-1, 0, 0)); Now for the algorithm proper, we can think of it in two parts, the first part is the initial iteration. Here we assign each pixel to the cluster nearest to it:
for (long x = 0; x &amp;lt; image.get_size().x(); &#43;&#43;x) for (long y = 0; y &amp;lt; image.get_size().y(); &#43;&#43;y) { auto&amp;amp; pixel = image(x, y); // find cluster with minimum distance  int min_distance = std::numeric_limits&amp;lt;int&amp;gt;::max(); size_t min_cluster_i = -1; for (size_t i = 0; i &amp;lt; clusters.size(); &#43;&#43;i) { // compute mean color of all cluster pixels  auto current_distance = distance(pixel, clusters.at(i).mean_color); if (current_distance &amp;lt; min_distance) { min_distance = current_distance; min_cluster_i = i; } } // assign pixel to cluster, .red() component is cluster index  pixel.red() = min_cluster_i; } We could end the algorithm right now and we would have a decent segmentation however this relies entirely on the heuristically chosen cluster centers and there is no guruantee the clusters would trend towards optimality. We achieve a decent approximation of this behavior (achieving proper optimality is NP-hard) by iteratively checking each pixel again and if there is a cluster that&amp;rsquo;s a better fit for it, we reassign it. After each iteration, we recompute the current mean cluster color meaning the clusters will change a little each iteration until convergence is achieved.
size_t n_changed = -1; // number of pixels that changed cluster this iteration  while (n_changed &amp;gt; 0) { n_changed = 0; for (long y = 0; y &amp;lt; image.get_size().y(); &#43;&#43;y) { auto&amp;amp; pixel = image(x, y); // find cluster with minimum distance  int min_distance = std::numeric_limits&amp;lt;int&amp;gt;::max(); size_t min_cluster_i = -1; for (size_t i = 0; i &amp;lt; clusters.size(); &#43;&#43;i) { // compute mean color of all cluster pixels  auto current_distance = distance(pixel, clusters.at(i).mean_color); if (current_distance &amp;lt; min_distance) { min_distance = current_distance; min_cluster_i = i; } } // get cluster pixel is currently assigned to  int old_i = pixel.red(); // reassign  if (old_i != min_cluster_i) { auto&amp;amp; old_cluster = clusters.at(old_i); auto&amp;amp; new_cluster = clusters.at(new_i); old_cluster.n -= 1; old_cluster.color_sum -= pixel; new_cluster.n &#43;= 1; new_cluster.color_sum &#43;= pixel; } // else do nothing  } // update clusters  for (auto&amp;amp; cluster : clusters) cluster.mean_color = cluster.color_sum / cluster.n; } It can be shown [TODO] that if ties (that is two clusters have the exact same distance to a single pixel) are resolved arbitrarily but each pixel is only assigned to one cluster this algorithm will always converge.
[TODO: convergence with images after each cluster]
The Heuristic In proper statistics it is common to run the algorithm multiple times with different number of cluster centers. Some even randomize the cluster centers completely and the solution is achieved by testing convergence between different entire runs rather than iterations within the same run. In image segmentation this is not available to us, usually the viewer will a) know how many principal color clusters there are in an image and b) will not have the memory nor time to do multiple executions. This means we basically need to nail it on the first try.
]]></content:encoded>
    </item>
    <item>
      <title>A (personal) modern C&#43;&#43; Styleguide</title>
      <link>http://clemens-cords.com/post/c&#43;&#43;_style_guide/</link>
      <pubDate>Mon, 17 May 2021 22:00:00 UT</pubDate>
      <dc:creator>C. Cords</dc:creator>
      <guid>http://clemens-cords.com/post/c&#43;&#43;_style_guide/</guid>
      <description>Quickstart  skip to here for a fully syntax highlighted code example that has all the possible cases Introduction  People, especially outside of CS, often think of code as purely utilitarian. It&amp;rsquo;s like a machine or a tool, it doesn&amp;rsquo;t matter how dirty it is inside, as long as it works and if it breaks you can call someone to fix it, it&amp;rsquo;s the best it can be. While this may be the case for a pneumatic borer I would urge everyone to consider source code asthetically equivalent to a dissertation, a pamphlet or an instruction guide and any piece of code should have the same care and effort put into it&amp;rsquo;s formatting and presentation as into more traditional documents.</description>
      <category domain="http://clemens-cords.com/categories/programming">Programming</category>
      <content:encoded><![CDATA[Quickstart  skip to here for a fully syntax highlighted code example that has all the possible cases Introduction  People, especially outside of CS, often think of code as purely utilitarian. It&amp;rsquo;s like a machine or a tool, it doesn&amp;rsquo;t matter how dirty it is inside, as long as it works and if it breaks you can call someone to fix it, it&amp;rsquo;s the best it can be. While this may be the case for a pneumatic borer I would urge everyone to consider source code asthetically equivalent to a dissertation, a pamphlet or an instruction guide and any piece of code should have the same care and effort put into it&amp;rsquo;s formatting and presentation as into more traditional documents. The main reason for this is to allow for cooperation, it&amp;rsquo;s always nice to have good documentation but if someone new joins the team knowing nothing about how things are done and they&amp;rsquo;re tasked to fix something rather than just use it their success and speed of accomplishing this mainly depends on how well maintained the code is. This way pretty code not only shows that you take pride and care in your work but also increases productiveness far, far into the future.
I would like to quickly break down my philosophy of what makes good practice and code style. The most important things are (in order starting with most important):
 Consistency: If you format something a certain way and you think it&amp;rsquo;s the best way to do it, format it that way every single time Clarity: Assume your audience has a very hard time understanding any code and try to make it easy to understand for them, not your well-trained doctorated senior dev Adaptability: Try to stay with the most up-to-date-way of doing things and if someone shows you a better way to do things, adopt it without question Elegance: Assuming maximum clarity and correctness the most elegant way to do something is the right way.  Table of Contents
0. Quickstart
1. Loops &amp; Brackets
2. Variables
&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp2.1 Naming
&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp2.2 Declaration
3. Operators
&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp3.1 References and Pointers
&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp3.2 Logical Operators
&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp3.3 Numerical Operators
&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp3.4 Pre- and Postfix Increment
4. Functions
&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp4.1 Member Functions
&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp4.2 Lambdas
&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp4.3 Auto-deducing Return Types
5. Classes &amp; Enums
&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp5.1 Naming
&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp5.2 Class vs. Struct
&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp5.3 Order of access-specified members: .hpp vs .cpp
&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp5.3.1 Filenames
&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp5.3.2 Template for Header-only Libraries
&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp5.3.3 Template for Non-Header-Only
6. Comments &amp; Documentation
&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp6.1 In-File Documentation
&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp6.2 Comments
&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp6.3 Choice of Variable/Function Names
7. Closing Remarks
&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp7.1 Version Control
&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp7.2 Testing and Profiling
&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp7.3 When Optimization is not Appropriate
&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp7.4 The Golden Rule: Always Refactor Once
8. Thanks and References
Loops &amp; Brackets Let&amp;rsquo;s get the omnipresent stuff out of the way first:
If present at all, brackets after if-else, while, for, try-catch and similar loops as well as blocks, non-lambda functions, classes, structs and enums should always have a newline before the first bracket as such:
// wrong enum { MEMBER_1, MEMBER_2 }; class foo { inline Foo() { for (auto&amp;amp; i : unmentioned_member) { initialize(i); }; } inline void bar() { return 1; } inline void empty_function() { } } // correct enum { MEMBER_1, MEMBER_2 }; class foo { inline Foo() { for (auto&amp;amp; i : unmentioned_member) { initialize(i); }; } inline void bar() { return 1; } }  The only exceptions to this are namespaces and lambdas with only one line of code inside of them as empty blocks. These should be opened and closed in the same line:
namespace style_guide::inside { Foo::Foo() {} // newline before the first bracket but closed in the same line  Foo::Foo(ArgumentType arg) : _member_a(//...),  _member_b(//...),  _other_member([&amp;amp;]() -&amp;gt; MemberType&amp;amp;&amp;amp; // newline because lambda body has more than one line of code  { do_something_else(); return std::move(MemberType(arg)); }()), _member_c(//...)  { std::sort(member_a.begin(), member_a.end() [](auto a, auto b) { return a &amp;gt; b; }); // no newline because it is one line  } }  Note how the multi-line lambda in the constructor is indented the same as the other _members in the trailing initializer list.
Now this decision is pretty arbitrary and it&amp;rsquo;s kind of a toincoss wether an individual dev will do newline-before or newline-after for curved brackets but I&amp;rsquo;d still like to give some context: I think the main reason to do after is to force devs to put a basically empty line after the first statement. This helps distinguish between function/class definitions and regular statements and it also makes it easier to find the start of the loop. Basically what I&amp;rsquo;m trying to say is:
// messy namespace space { ClassName : public Mother { ClassName() = default; ClassName(ArgType arg) : ClassName() { } } } // clearer namespace space { ClassName : public Mother { ClassName() = default; ClassName(ArgType arg) : ClassName() {} } } // equally clear though: namespace space { ClassName : public Mother { ClassName() = default; ClassName(ArgType arg) : ClassName() { } } }  What&amp;rsquo;s important isn&amp;rsquo;t the bracket but the empty or almost empty line after the declaration. The reason I pick newline-before is because for constructors like in the above example I like the opening bracket for the CTOR definition to not be inline with one of the initializer list statements, with normal functions it can&amp;rsquo;t get lost but with CTORs it can in all the brackets of the initializer list:
Foo::Foo() : LambdaMember2([&amp;amp;]() { auto res = multiline_lambda(); res &#43;= multiline_lambda(); return res; }(), LambdaMember([&amp;amp;](){ return oneline_lambda();}()) { }  Is very hard to parse. With the bracket starting the ctor definition preceded by a newline it is much easier and if you&amp;rsquo;re doing the newline-before in one situation you should do it always because as I said, consistency is the most important thing.
Variables The following variable naming scheme should be adhered to at all times in most C-based languages unless language specifics prohibit:
 Scope Qualifier Naming Example   local class-, function- or internal namespace scope non-const or const  lower-case snake_case
  size_t not_a_member;
   global scope non-const or const all-caps snake_case  static InputHandler INPUT_HANDLER;
#define PI 3.14159
   public member non-const lower-case snake_case  Vector2f top, left;
   public member const all-caps snake_case  const size_t MAX_THREAD_COUNT = 64;
   private or protected member non-const or const lower-case snake_case with prefix &#34;_&#34;  std::string _id;
static Color _default_color;    Some variables gain a pre- or postfix depending on their type as such (the above naming scheme still applies):
 Type Name   unsigned int index i, j, ... or foo_i, foo_j, ...   unsigned int counter n_foo   bool is_foo, should_foo, can_foo, etc.   Type* foo_ptr   Type::Iterator foo_it   Color foo_rgb, foo_rgba, foo_hsv, foo_hsva, etc.   Angle in [0, 360] or [0, 2&amp;#960] foo_dg, foo_rad   Percent in [0%, 100%] foo_pct   typename or using/typedef declaration name  Foo_t    Declaration The order of type qualifier should always adhere to the following priorites (where 0 is the left most qualifier) 0: static 1: inline, extern 2: mutable 4: volatile 5: constexpr, consteval, const 6: Type of the variable &amp;lt;no space&amp;gt; 7: &amp;amp; or * or &amp;amp;&amp;amp; &amp;lt;space&amp;gt; 8: Name of the variable // for example static inline const foo* const ptr = //... extern mutable volatile const auto* var = //... 
In easier to remember terms: always put static fist, always group const as right as possible but before the variable type and name. It&amp;rsquo;s rare for this many qualifiers to pile up but it&amp;rsquo;s good to have a solid idea of where stuff goes should the time come.
Any variable that explicitely calls a constructor or other function on the right hand-side of the declaration should have the type auto.
// wrong: Vector2f vec = Vector2f(20, 50); Vector2f vec = create_vector(20, 50); Vector2f vec(20, 50); // correct: auto vec = Vector2f(20, 50); auto vec = create_vector(20, 50);  This is to avoid confusion with C&#43;&#43;20s new aggregate initialization with round brackets as it is not immediately obvious which of these the following statement tries to invoke:
Vector2f foo();  I could be either calling the default constructor of Vector2f with c&#43;&#43;20 aggregrate initialization with round brackets and no arguments or forward declaring a function with return type Vector2f and no arguments. Using
auto foo = Vector2f();  makes it immediatly obvious.
For trivial numeric types, always use float for floating points. 64-bit numbers like double should be a conscious decision on the developers part when they recognize that they need the extra precision, not the default. This is to avoid unnecessary overhead on certain cpu architectures or in bleeding-edge-performance environment.
Be aware of potential overhead this may cause by casting up or down the precision hirarchy when interacting with other libraries. clang-tidy usually issues a warning for this and it should not be ignored.
On the topic of casting, static_cast should always be preferred over c-style casts, even for trivial numeric type:
double high_precision = 2.2153165231; // wrong float low_precision = float(high_precision); float low_precision = (float) high_precision; auto low_precision = float(high_precision); float low_precision = static_cast&amp;lt;float&amp;gt;(high_precision); // correct auto low_precision = static_cast&amp;lt;float&amp;gt;(high_precision);  If multiple variables of the same type and type-qualifier are declared one after another, always use the init-declarator-list form as such:
std::string first_name, last_name, adress; Foo *ptr_one, *ptr_two; Bar &amp;amp;ref; Bar not_ref;  There should always be a newline after the first declaration. If one of the variables is a pointer, reference, r-value, etc. then all of them should have the same type qualifier. If this is not the case, the type should be explicitely redeclared in a new line.
This form reduces redundant words be redeclaring the type over and over and makes it easy to group members or variables by type on first glance.
I would make an exception if all variables names are very short words, consider: // version 1 struct Color { float r, g, b, a; } // version 2 struct Color { float r, g, b, a; } 
I would not reject a pull request with version 1 however I would also not ask someone using version 2 for consistency to change the formatting to version 1. Make of that what you will.
Operators Reference, Pointer, R-Value-Reference, etc. In function arguments and any other variable delcaration there should be a space following the &amp;, *, &amp;&amp; qualifiers but not preceding it: Foo&amp;amp; wrap_foo(const Foo* const foo_ptr, Foo&amp;amp;&amp;amp; foo_rvalue, const Foo&amp;amp; foo_ref) { // ... } std::vector&amp;lt;Foo&amp;gt;* foo_vec_ptr = // ... for (auto&amp;amp; foo : *foo_vec_ptr) { // ... }  I am aware this is an onpupolar choice so let me explain: When we read out code in real life meaning actually read it out loud to someone in the same room, when someone asks us: &amp;ldquo;What is the type of const Foo* bar?&amp;rdquo; we answer &amp;ldquo;constant foo pointer&amp;rdquo; or &amp;ldquo;a pointer to a constant foo&amp;rdquo;. It&amp;rsquo;s the same the same with references, r-values, etc.. I consider the type qualifier to be part of the type and it should thus be grouped with the type in the declaration.
I will admit this falls apart when using the above mentioned init-declarator-list:
const Foo&amp;amp; first, // type Reference to a const Foo  second, // type const Foo  *third, // type Pointer to a const Foo  *fourth const; // type constant Pointer to a constant Foo  which is why I stated that when using this form, all variables should have the same type and type qualifier.
Logical Operators  Always use and, or, not instead of &amp;amp;&amp;amp;, ||, ! for boolean operands.
Always use &amp;amp;, |, ^, ~ instead of bitand, bitor, xor, compl for numerical operands. Similarly always use &amp;amp;=, |=, !=, ^= over and_eq, or_eq, not_eq, xor_eq for these operands.
It may be my lua background but I&amp;rsquo;m fond of the and, or, not in boolean expressions, many people from non-cs fields that primarily work in matlab or another very high level scripting language will have an easier time reading complex boolean expressions and using the keywords eliminates typos where the bit-wise logical operators are used accidentally triggering not error but performance overhead from non-short-circuiting expressions.
Numerical Operators There should be a space preceding and following the binary operators &#43;, -, /, %. The unary - should be used on variables as well as number constants in favor of -1 * 
int a, b; // wrong: c = 2*(a&#43;b); c = a*b; c = -1*a; c = std::modulus(a, a%b); // correct: c = 2 * (a &#43; b); c = a * b; c = -a; c = a % (a % b)  Unless in performance critical code conditions where every operation counts it is sometimes preferable to not mathematically simplify formulas for something if it aids in clarity.
Pre- and Postfix Increment Prefix incremenet / decrement should always be preferred over the postfix option unless specifically necessary to produce desired behavior:
size_t n = 0; // wrong: for (auto it = vec.begin(); it != vec.end() or n &amp;lt; 15; it &#43;= 1, n&#43;&#43;) // ...  for (auto it = vec.begin(); it != vec.end() or n &amp;lt; 15; it.operator&#43;&#43;(1), n&#43;&#43;) // ...  // correct: for (auto it = vec.begin(); it != vec.end() or n &amp;lt; 15; &#43;&#43;it, &#43;&#43;n) // ...   In many scenarios, post- and prefix operators are functionally equivalent but in that 1% of cases in which they aren&amp;rsquo;t using the wrong one may cause hard-to-catch bugs. Always defaulting to the prefix version tends to avoid this as much as possible.
Functions All function names should be lower-case snake_case. This includes lambdas however functors should be named according to the class naming specification (c.f. below). On declaration without definition, function arguments should be unnamed unless specifically necessary to give context or if there are multiple arguments of the same type:
// wrong void set_position(Vector2f position); void add_percentage(float); // expects [0, 1], not [0, 100] void set_name(std::string, std::string); // correct void set_position(Vector2f); void add_percentage(float zero_to_one); void set_name(std::string first_name, std::string last_name);  Member Functions Members functions that set one or more member variables should always be named set_* where * is the same name used when declaring the member in the .hpp source code.
class Color { private: float _r, _g, _b, _alpha; public: void set_rgb(float, float, float); void set_alpha(); // wrong:  void set_red(float); // correct:  void set_r(float; }  Similarly, getters should always be named get_*, however if the function returns a single bool, if that bool is a member variable named _is_foo it&amp;rsquo;s getter should be named get_is_foo(), however if that value is not a member it&amp;rsquo;s getter should be phrased like a yes-or-no question, for example:
class OsWindowHandler; class RenderWindow { private: std::string _id; bool _is_closed = false; public: void set_closed(bool b) { _closed = b; } bool get_is_closed() const // member bool  { return _closed; } bool is_focused() const // non-member bool  { return OsWindowHandler::is_window_focused(_id); } bool should_notify_on_close() const // non-member bool  { return OsWindowHandler::get_context_settings(__id).should_notify_on_close; } }  Lambdas Lambdas are very powerful in modern C&#43;&#43; and it can be very attractive to not add a new member function and instead just open a local lambda function inside another function. Lambdas should be used only where necessary, if you would call the potential member function from 2 or more places it&amp;rsquo;s almost never worth it to not just create the new function.
If you do have to use a lambda, if the lambda function itself is only called once inside it&amp;rsquo;s scope, consider making it anonymous, the most common place would be inside a set or sorting algorithm with a custom comparison. If more than 1 routine needs it and it needs to be a lambda, consider making it a member and binding it to an std::function;
A place I like to employ lambdas is for inline static initialization. Sometimes you need to call functions that do not return the object you&amp;rsquo;re trying to initialize like so:
class TexturedFoo : public Drawable { private: const Texture _texture; static inline const _window_resolution = []() { if (not RenderWindow::is_initialized()) RenderWindow::initialize_from_config(); return RenderWindow::get_resolution(); }(); public: TexturedFoo(std::string texture_id) : _texture([&amp;amp;]() -&amp;gt; Texture&amp;amp;&amp;amp; { auto texture = new_texture(); if (not texture.load_from_file(texture_id)) throw /... return std::move(texture); }()) {} }  I think this can be a very elegant way to initiate things that need a more complex routine than just calling it&amp;rsquo;s constructor, however thought should be put into wether it really is necessary to make this a lambda.
For the above example both initialization functions could just be a static member function of RenderWindow and Texture respectively and I would again argue that the lambda is only justified if that behavior is only called exactly once in the entirety of the library.
When using lambdas it&amp;rsquo;s almost always best to delcare them as [&amp;amp;](auto arg1, auto arg2) { //&amp;hellip;  nowadays. This way the compiler will decide which variables to capture themself and the argument type is automatically deduced. The capture should only be manually specificed if for example the invocation of a copy constructor is necessary. Similarly the trailing return-type  [&amp;amp;](auto arg1, auto arg2) -&amp;gt; foo { //&amp;hellip; should be ommitted unless specifically necessary.
I would advise you to check on the lambda docs page every year or so, it feels like the new C&#43;&#43; versions, C&#43;&#43;20 just recently and C&#43;&#43;23 recently, are very impactful on what is possible with lambdas and I would encourange everyone to try to stay up to date with the most recent way of doing things, most recently templated lambdas and constraints/concepts support.
Auto-deducing return types  It&amp;rsquo;s tempting to always declare the return-types as auto if possible, even if it&amp;rsquo;s not strictly necessary. It may often seem like the most modern way to do things but I would advise caution. If proper documentation isn&amp;rsquo;t done yet it can send potential collborators on the hunt through your function definition to find out what exactly your function returns anyway. Without auto one look at the function declaration would&amp;rsquo;ve sufficed. In my opinion, if auto is possible the following form should be used:
// wrong: template&amp;lt;typename Return_t&amp;gt; auto create_function() { return std::move(std::function&amp;lt;Return_t()&amp;gt;()); } // better: template&amp;lt;typename Return_t&amp;gt; std::function&amp;lt;Return_t()&amp;gt;&amp;amp;&amp;amp; create_function { return std::move(std::function&amp;lt;Return_t()&amp;gt;()); } // best: // @brief dummy function // @returns rvalue of type function&amp;lt;Return_t()&amp;gt; template&amp;lt;typename Return_t&amp;gt; auto create_function() { return std::move(std::function&amp;lt;Return_t()&amp;gt;()); }  By employing good in-code documentation the original dev gets to use the convenience of auto and the collaborators only have to take one look at the function declaration to know what type the function returns. In cases were returning auto is absolutely necessary (such as when the return type depends on template parameters outside the developers control) other than proper documentation there is no way of getting around needing to see the definition to truly understand what&amp;rsquo;s happening.
Classes &amp; Enums Naming Classes, Enums and other class-like entities are always named upper-case CamelCase. This includes structs, unions, enums, typenames and typedefs as well as using-declarations for any of these entities.
Enums As all Enum &#34;members&#34; are inherently scoped static constexpr constants, they should be in all-caps SNAKE_CASE. When each enumerator is manually defined with an expression, the enums type should also be manually defined as such: // wrong: enum Manual : int {ZERO, ONE, TWO} enum Manual {FIRST = 1, SECOND = 2, THIRD = -2} // correct: enum Manual {ZERO, ONE, TWO} // auto deduces int enum Manual : int {FIRST = 1, SECOND = 2, THIRD = -2}  An enum that&amp;rsquo;s inside the global namespace should be declared a scope enum enum class Foo. This is to avoid name-collisions which can be very annoying when an unrelated library you&amp;rsquo;re using already reserved an enum constant name you want but they didn&amp;rsquo;t scope their enum properly. If an enum is only used inside a very limited scope it is fine to omit the class for the convenience of not having to specify 3 scopes before using an enum constant.
namespace MyLibrary { // use enum class  enum class PublicEnum { //...  namespace detail { // no enum class okay  enum DetailEnum { //...  } class Class { private: // also okay  enum PrivateEnum { //...  } } // never put an enum in global namespace  Class vs. Struct If all member variables and functions of a user-defined type are public, struct should be used an no access specifiers (public, protected, private) should be stated.
In all other cases, class should be used and all members should be manually access specified.
// wrong: struct HSV { public: float _h, _s, _v; } struct Color { HSV to_hsv() const; private: float _r, _g, _b, _alpha; } // correct: struct HSV { float h, s, v; // no _ because members are public } class Color { public: HSV to_hsv() const; private: float _r, _g, _b, _alpha; }  File Organization: .hpp and .cpp Filenames  All programming language files should be lower-case snake_case. If a header holds a class named FooClass, the header should be named foo_class.hpp and similarly the source file should be foo_class.cpp.
If FooClass contains and internal class FooInternal declared in the same header then there should be a seperate second .cpp named foo_internal.cpp. This avoids having to recompile both classes when only changing something in one of them.
.h should not be used unless the entire header is exclusively written in C, not C&#43;&#43;. For files in other programming languages the most common programming language file-extension should be used, for example if your data representation for a video-setting file is in lua and you agreed on a .cfg file extension for configs, the file should be name video_settings.cfg.lua. Many programming and data representation languages do not care what their file is name but you should still take care to make it immediatly obvious what language a file is written in, collaborators should not have to open the file in notepad and try to figure out the language. Here is a non-exhaustive list of languages and file extensions I personally use:
 Language Extension   C&#43;&#43;  .hpp for headers
.cpp for source files    Python  .py    Java  .java    JavaScript  .js    Lua  .lua    Ruby  .rb    Perl  .pl    Go / Golang  .go    R  .R    GLSL  .glsl
.frag for Fragment Shaders
.vert for Vertex Shaders
   Data Representation: CSV  .csv    Data Representation: XML  .xml    Data Representation: Lua  .sav.lua for savefiles
.cfg.lua for config
etc.
   Data Representation: JSON  .json    Data Representation: Matlab  .MAT    I think a lot of these are standard and there&amp;rsquo;s surely many I&amp;rsquo;ve missed like all the html-related things like .md and .css but the point of this list was more to instill in you a point of consistent flexibility. If it doesn&amp;rsquo;t matter to the computer the extension is technically arbitrary, but the human part of your company should decide one exactly one answer anyway and stick to that at all times. If that answer overrides the script languages default extension like I do with .lua, it should be .yourextension.lua to allow people from outside your team to easily classify your files too.
Classes: Declaration and Definition I might be wrong on this but afaik in modern C&#43;&#43; the only reason to use the .hpp for declaration and .cpp for definition for a non-templated class is to reduce compile time. I&amp;rsquo;ve asked this question to multiple people and nobody was able to give me a solid answer, for cyclic linkage and multiple definition errors you can inline functions in the .hpp and static members you can also inline to allocate them without a .cpp. Furthermore templated classes require the definition to be in a .hpp anyway so it&amp;rsquo;s very confusing. This is how I&amp;rsquo;ve been doing it so far and it kinda depends on a decision made at the very beginning of development:
Header-only library If the library is header-only there should not be a single .cpp anywhere. The following form should be used:
Inside the same access-specifier (private, protected, public) region, the declarations immediately followed by the definition should be in the following order:
 using / friend class declaration static member variables non-static member variables Constructor, Destructor, Copy- and Move-Constructors Assignment operators other operators static member functions non-static member functions  Inside the class the access-specified regions should be in the following order:
 private protected public  All functions should be defined inline, for non template files the inline keyboard should be used. Similarly all static members, both in templated and non-templated classes, should be initialized inline. This may cause static initilizations to be sensitive to the order they&amp;rsquo;re declared in a file so be wary of that. If you&amp;rsquo;re not sure you can always use the construct-on-first-use idiom.
// template_foo.hpp template&amp;lt;typename First_t, typename... Args_t&amp;gt; class TemplateFoo : protected ParentFoo { private: static inline MemberType _static_private_member = //...  Function_t _private_member; void private_func(Args_t... members) const { // full definition here  } protected: using Function_t = std::function&amp;lt;First_t(Args_t...)&amp;gt;; static inline protected MemberType _protected_member = //..  MemberType2 _protected_member; template&amp;lt;typename T&amp;gt; First_t protected_func(T) { // full definition here  } public: static inline constexpr float PUBLIC_CONST_FOO = 42; float x, y; Foo() = default; Foo(Args_t...) = default; // &#43; dtor, move-assignment, copy-constructor, etc.  static float static_function() { // full definition here  } auto get_private_member() const { return _private_member; } } // non_template_foo.hpp class NonTemplateFoo : public TemplateFoo&amp;lt;int, int&amp;gt; { private: static inline int member = TemplateFoo&amp;lt;int, int&amp;gt;::static_function(); public: inline void NonTemplateFoo() { // full definition here  } }  Advantages of this form include an easier time linking things, being able to access the source code directly by just following back the header you included and less duplicated elements because you do not have to redeclare the template for every external definition. Disadvantages include far larger compile time and the fact an IDE is needed so collaborators can collabls longer functions or internal classes to rapidly access all declared functions signatures without having to scroll through thousands of lines. If that last point doesn&amp;rsquo;t fully make sense, let&amp;rsquo;s compare with the non-header only format:
Not Header-only Library If the library has at least one .cpp it is not header only and the following form should be used for all interal files from your library:
Inside the same access-specifier members should be declared in the following order:
 using / friend class declaration static member variables non-static member variables Constructor, Destructor, Copy- and Move-Constructors Assignment operators other operators static member functions non-static member functions  Inside the class the access-specified regions should be in the following order:
 public protected private  Note that this is inverted when compared to header-only libraries. This is because in non-header-only libraries the class body should exclusively contain declarations. All functions and static members should be defined in the .cpp or if that is not possible (for example because the class is templated) they should still only be declared in the class definition and then defined later in the .hpp as such:
// template_foo.hpp template&amp;lt;typename T&amp;gt; class TemplateFoo : public ParentFoo { public: TemplateFoo(); float get_member(); void set_member(float) const; protected: static Type _protected_member; private: void private_function(); float _private_member; } // ###################################################################  template&amp;lt;typename T&amp;gt; Type TemplateFoo&amp;lt;T&amp;gt;::_protected_member = // ...  template&amp;lt;typename T&amp;gt; TemplateFoo&amp;lt;T&amp;gt;::TemplateFoo() { // full definition } template&amp;lt;typename T&amp;gt; float TemplateFoo&amp;lt;T&amp;gt;::get_member() const { return _private_member; } template&amp;lt;typename T&amp;gt; void TemplateFoo&amp;lt;T&amp;gt;::set_member(float f) { _private_member = f; }  // non_template_foo.hpp class NonTemplateFoo : public ParentFoo { public: NonTemplateFoo(); float get_member(); void set_member(float) const; protected: static Type _protected_member; private: void private_function(); float _private_member; } // non_template_foo.cpp Type NonTemplateFoo::_protected_member = // ...  NonTemplateFoo::NonTemplateFoo() { // ... } float NonTemplateFoo::get_member() { return _private_member; } void NonTemplateFoo::set_member(float f) { _private_member = f; } void NonTemplateFoo::private_function() { // .. }  Advantages of this form include improved readability as with just one look a collaborator can get all the relevant external information about a class. Further compile-time is vastly improved which I&amp;rsquo;d like to put into context here because this point is honestly mostly dependent on personality.
Compile time is usually just seen as a necessary evil and since the user will most often not have to compile your product it&amp;rsquo;s somewhat irrelevant for the economical process, right? Well anytime your machine is compiling you&amp;rsquo;re not doing anything else. If this is just for a small app you only loose seconds which is irrelevant but if it&amp;rsquo;s for a big highly interlinked app and especially if either your machine is slow and/or you use a lot of compile-time execution (which you should nowadays) things can add up fast. For my biggest project recompiling all modules on my somewhat-decent laptop can take upwards of 90s. In an environment where rapid iteration is needed this can add up fast and I can imagine is a big reason people tend to gravity towards scripting language that don&amp;rsquo;t need to compile nowadays. No matter how you stand on the issue of compile time, wether you split the .hpp or you don&amp;rsquo;t is up to preference but you do have to decide early on stick to it. Again consistency is the most important thing, if you do something badly but the same everytime it&amp;rsquo;s easier understood than using 20 different elegant solutions that don&amp;rsquo;t look alike.
Comments &amp; Documentation In-File Documentation Unless otherwise dictated by the documentation API your project uses, the following form should be employed for all public or protected functions:  Tag Is Optional Description   @brief Never Optional  Short description of what the function does. Should be one sentence    @param Optional if function has no parameters or functions exists in private context  Description of function argument follower by &amp;ltname_of_the_parameter:. If parameter is unnamed in delcaration, the name is ommitted and replaced with a number instead (see example below    @returns  Optional if function returns void or function exists in private context  Description of the returned value. If functions returns auto, explicit mention of the function return type    @author Always Optional  Handle of developer, this may be the real name or for example a github user name. Ask collborators if they are okay with having their full name distributed and always give credit in highly collaborative scenarios such as crowd-sourcing    (no tag) always optional  Verbose description of the functions. Always put last after all the tagged content right before the actual function declaration    // @brief mix two foos using the ratio // @param 1: First foo to merge // @param 2: Second foo to merge // @param ratio: ratio of first to second foo, [0, 1] // @returns rvalue reference to newly merge foo // // Functions takes two foos and applies (...) // (...) // (...) // returning the now coagulated foos as an rvalue reference Foo&amp;amp;&amp;amp; merge_foos(Foo&amp;amp;, Foo&amp;amp;, float ratio);  For private functions or functions and classes in namespace detail the documentation can be substituted with a single line like this: // @brief merge using ratio Foo&amp;amp;&amp;amp; merge_foos(Foo&amp;amp;, Foo&amp;amp;, float ratio); 
While it would of course be best to document everything it&amp;rsquo;s a reality of software development that proper documentation will happen last. That&amp;rsquo;s why some tags are optional, it&amp;rsquo;s an incentive for developers to at least do the one-line version however it is not an excuse to then never extend the one-line version. It&amp;rsquo;s a temporary solution but a better compromise than not documenting anything.
Comments In case you haven&amp;rsquo;t noticed so far, comments should be inline-comments of the form // this is a comment concerning the next line auto next_line = ...  Notice the space after //. All comments should start at the smallest indent of the block meaning there should never be a piece of code left of the comment and the comment should be appropriately indented as such:
// wrong: for (size_t x = 0; x &amp;lt; n_x; &#43;&#43;x) { for (size_t y = 0; y &amp;lt; 0.75 * n_x; &#43;&#43;y) // x:y ratio should be 4:3  { doo_foo(x, y); // ...  } } // correct: for (size_t x = 0; x &amp;lt; n_x; &#43;&#43;x) { // x:y ratio should be 4:3  for (size_t y = 0; y &amp;lt; 0.75 * n_x; &#43;&#43;y) { doo_foo(x, y); // ...  } }  All comments should be in-line comments. This is mostly a matter of prefrence but I do have a valid reason: When debugging you often want to disable a piece of the program by &amp;ldquo;commenting it out&amp;rdquo;, i.e. putting a multi-line comment around it temporarly. If there are already multiline comments in that section this will break the commented-out section up which means you have to add multiple comments just to comment something out for 10mins. An exception to this rule are comments at the very beginning of the file such as copy right disclaimers or similar legal-related things. As they are at the start of the file they can never interrupt multi-line comments. If you do decide to include multi-line comments in the release they should be formatted as such:
/* * There should be an empty line above the first line * An each line should start with an asterisk * (...) * (...) */  Choice of Variable/Function Names Let&amp;rsquo;s do a little hypothecial, first I&amp;rsquo;d like you to look at this code completely out of context. I intentionally choose variable names poorly but without malice, maybe I&amp;rsquo;m new or I really didn&amp;rsquo;t have time to do this so I just submitted my first draft as a pull request
class Base {}; class Wrapper : public WrapperBase { // ... }; Pool { void start(size_t); std::condition_variable _var; std::mutex _mutex; std::queue&amp;lt;std::unique_ptr&amp;lt;TaskWrapperBase&amp;gt;&amp;gt; _q; std::vector&amp;lt;std::thread&amp;gt; _w; bool _res, _shutdown, }; void Pool::start(size_t n) { assert(_t.empty()); for (size_t i = 0; i &amp;lt; n; &#43;&#43;i) { _t.emplace_back([&amp;amp;]() { auto lock = std::unique_lock&amp;lt;std::mutex&amp;gt;(_mutex, std::defer_lock); while (true) { lock.lock(); _cv.wait(lock, [&amp;amp;]() -&amp;gt; bool { return _res || !_queue.empty() || _shutdown; }); if (_res || (_shutdown &amp;amp;&amp;amp; _queue.empty())) { return; } auto t = std::move(_queue.front()); _queue.pop(); lock.unlock(); t-&amp;gt;operator()(); } }); } }  What happens in this code? I&amp;rsquo;m sure many of you will be able to figure it out eventually but this isn&amp;rsquo;t a pop-quiz, it&amp;rsquo;s simply a demonstration of what a difference code-style can make to a third party. Let&amp;rsquo;s look at the same code again but overly commented in a vein effort to explain what is happening:
// empty base needed for unique pointer class Base {}; // Wraps tasks class Wrapper : public WrapperBase { // ... }; // variable size thread pool Pool { public: // ...  private: // initialize threads  void start(size_t); std::condition_variable _var; std::mutex _mutex; std::queue&amp;lt;std::unique_ptr&amp;lt;TaskWrapperBase&amp;gt;&amp;gt; _q; // task queue  std::vector&amp;lt;std::thread&amp;gt; _w; // worker threads  bool _res, // is threapool paused for resizing?  _shutdown, // is threapool shutting down? }; void Pool::start(size_t n) { for (size_t i = 0; i &amp;lt; n; &#43;&#43;i) { // add thread with routine  _t.emplace_back([&amp;amp;]() { // create lock for queue  auto lock = std::unique_lock&amp;lt;std::mutex&amp;gt;(_mutex, std::defer_lock); // keep checking if new task for taskqueue is ready  while (true) { lock.lock(); // wait at conditional variable until notified  _cv.wait(lock, [&amp;amp;]() -&amp;gt; bool { return _res || !_queue.empty() || _shutdown; }); // finish routine when resizing or shutting down  if (_res || (_shutdown &amp;amp;&amp;amp; _queue.empty())) { return; } // then get task  auto t = std::move(_queue.front()); _queue.pop(); lock.unlock(); // and run it  t-&amp;gt;operator()(); } }); } }  This is prefectly understandable, I think most people will immediately know whats going on and it could be argued that&amp;rsquo;s the only thing that counts but I would like you to remind of one of the goals of this style guide: elegance. Comments are not elegant, because operating under the paradigm of &amp;ldquo;only comment when absolutely necessary&amp;rdquo; we can rewrite the code without sacrificing clarity like so:
class TaskWrapperBase {}; class TaskWrapper : public TaskWrapperBase { // ... }; ThreadPool { public: // ...  private: void initialize_worker_threads(size_t); std::queue&amp;lt;std::unique_ptr&amp;lt;TaskWrapperBase&amp;gt;&amp;gt; _task_queue; std::condition_variable _queue_conditional_variable; std::mutex _queue_mutex; std::vector&amp;lt;std::thread&amp;gt; _worker_threads; bool _is_paused_for_resizing, _is_shutting_down; }; void ThreadPool::initialize_worker_threads(size_t n_threads) { for (size_t i = 0; i &amp;lt; n_threads; &#43;&#43;i) { _worker_threads.emplace_back([&amp;amp;]() { auto queue_lock = std::unique_lock&amp;lt;std::mutex&amp;gt;(_queue_mutex, std::defer_lock); while (true) { queue_lock.lock(); _queue_conditional_variable.wait(queue_lock, [&amp;amp;]() -&amp;gt; bool { return not _task_queue.empty() or _is_paused_for_resizing or _is_shutting_down; }); if (_is_paused_for_resizing or _is_shutting_down and _task_queue.empty()) return; auto new_task = std::move(_task_queue.front()); _task_queue.pop(); queue_lock.unlock(); new_task-&amp;gt;operator()(); } }); } }  I think it is appropriate to say that this version is just as clear and easy to understand as the commented version except this time the reader actually looks at the code. Someone trying to debug the first version will ignore the code completely on their first read because they don&amp;rsquo;t need it to understand what&amp;rsquo;s even going on but when they do they still have to deal with obtuse variable names. Using the more elegant minimally commented version allows for less fluff at no cost of clarity.
Closing Comments Here are some things I didn&#39;t know where to put structurally but that I still think are important to say: Version Control Commit as often as possible. Anytime you change file or continue to the next step of implementing/fixing something, create a new commit. The actual commit message should be what was just done, past-tense, not what you&#39;re about to do. The more granular the commits are the easier it will be to rollback when something goes wrong and similar to documentation well formatted messages will help you understand things instantly even 2 years later. Consider coming up with a labeling scheme each message begins with, I often see things like [FIX], [POLISH], [TYPO], [ISSUE#1234] etc.. Some teams even uses emotes which I do kinda like but not all shells support this so maybe alphanumerical would be better for now.
You&#39;d think having a million commits would get hard to manage but that&#39;s what pull-requests are for. They collapse all the tiny commits into one big package and by grouping them like this you both get the convenience of having the granularity on your machine but once it goes to the team or users they don&#39;t have to sift through pages and pages of messages to rebase. Test and Profile Frequently Testing modules frequently is non-negotiable. I recommend google test but an internal testing framework can also be used. Testing assures correctness and it can be used later to see if modules would interact properly were this new feature merge with the master.
Test small pieces of modules, you don&#39;t need to write a test for every function but a test should take no more than 5mins to finish. If you do need testing in general to run for 30mins should should create 6 smaller tests and run them sequentially. That way if you only change one part you don&#39;t need to run the giant test again to see if it works now. Profiling and Benchmarking are a more sublte issue because they aren&amp;rsquo;t always necessary in my opinion. For certain application yes, you should absolutely benchmark and especially if you&amp;rsquo;re currently trying to optimize already existing code the only way you can do that properly is to actually benchmark the code by running it to see if it actually got faster. There are best-practice ways for this such as using a steady machine or running benchmarks multiple times and using statistical analysis on the results but I won&amp;rsquo;t go into that here.
Don&amp;rsquo;t think you can spot performance problems just by re-reading code, always run it even if you have three doctorates and 40 years of experience humans make errors or overlook things no matter how good they are at what they do. Having solid proof of how things are better now in forms of data is also a better way to convince customers or collaborators that what you did was actually successfull.
I do realize that this can be overkill, you don&amp;rsquo;t need to squeeze out that last 5% performance increase for your app that starts a washing machine in your house. A good middle-ground I found is to have a profiling tool run in the background. For example for my game I have a seperate process that monitors how much time of the 1/60ths of a second (the duration of one frame) the rendering and simulation needs and how much time the engine has just waiting for the monitor to refresh. If nothing happens that index is at 0%, if the engine is so slow that it lags the screen the tool will notify me that the percentage is above 100%. I always have that number on the side of my screen, that way when something doesn&amp;rsquo;t quite break but behaves unexpectedly non-performant I know to investigate. When Optimization is Appropriate On the topic of optimization, don&amp;rsquo;t always go for the optimal way of doing things unless it&amp;rsquo;s necessary. Again, some for some environments it&amp;rsquo;s true, always do it the fastest way that&amp;rsquo;s what counts but be realistic about it. If you for example want to allocate user made objects and access them later by ID and you expect the user to at most ever make 6 objects then writing a specially-hashed map that objects them in sub-logarithmic time is really not worth it vs just putting them in an array and iterating over all indices everytime you need to access them. Similarly I would always think first before parallelizing something. Anytime that decision is made, the reason should be &amp;ldquo;we can&amp;rsquo;t make it sequential because x&amp;rdquo;. Sequential should always always be default, parallelization is something that introduce so much complexity and hard-to-catch bugs that I would honestly recommend not doing anything in paralell until you&amp;rsquo;re read to release and then paralellizing thing to make everything snappier though this requires a good softwaredesigner because things have to be designed in a way that would work both sequential and in paralell from the beginning
Always Refactor at least once When you realize you accomplished your taks or fixed a bug, take some time to go through your code again to pretty it up. I often set myself goals like &#34;today I will implement x&#34; and then at the end of the day when I run my test and it goes through I&#39;ll go &#34;done for today&#34; and leave and then I never touch that file again until something goes wrong. This is not good, just because something works doesn&#39;t mean it&#39;s done. It&#39;s not even about adding documentation, sometimes redundant stuff will be left over or an if-else branch has duplicate branches or you forgot to delete a commented out section or I you slacked off and didn&#39;t 100% keep to the style guide rules detailed above. Always doing at least one refactor will do wonders to keep your code clean and most importantly the more you do this the more you will just do things properly the first time. I&#39;m still in this learning process myself but actually challenging what I do through force of habit will get me closer to doing it right the first time over time. Epilogue If you read this far through in one go then I would like to thank you for your time. The main point of this piece was less to inform (nobody is reading these anyway) but to investigate my own way of doing things. Writing everything out forces me to argue my points to the imagined reader and it helps me structure and maybe questions my ways of doing things and like I stated at the beginning, adaptability and a willingless to discard tradition in favor of better things are the 3rd most important thing you can do with your coding style. C.
 As I evolve I&#39;ll probably change and keep this update so here is a list of edits: First published, Mai 18th 2021 Added Bracket Chapter, Mai 28th 2021 Added &#34;don&#39;t use else&#34;, Mai 30th 2021]]></content:encoded>
    </item>
  </channel>
</rss>
